{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9cad3b-13b1-46e2-99f3-c8a177437ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os, dotenv, sys\n",
    "\n",
    "from utils.google_api_utils import gsheet_upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078febec-b4ff-4e69-bb4b-b5d6fc67f5cc",
   "metadata": {},
   "source": [
    "# Statement Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef46e7-282d-43d4-8257-099ebcfd464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the folder path for the statement datasets\n",
    "folder_path = \"../personal_envs/household-cashflow-analyzer/private/\"\n",
    "\n",
    "# get the account names\n",
    "account_list = []\n",
    "\n",
    "for name in os.listdir(folder_path):\n",
    "    if os.path.isdir(os.path.join(folder_path, name)):\n",
    "        account_list.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8877e26f-7186-42c1-9a1a-ff09747c3329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function of cleaning the Discover credit card\n",
    "def get_dis_cc(file_path):\n",
    "    df = pd.read_csv(file_path).rename(columns = {'Trans. Date': 'Date'})\n",
    "    df['Amount'] = -df['Amount']\n",
    "    df[\"date_str\"] = pd.to_datetime(df[\"Date\"], format=\"%m/%d/%Y\").dt.strftime(\"%Y%m%d\")\n",
    "    df[\"row_num\"] =  (df.groupby(\"date_str\").cumcount() + 1).astype(str).str.zfill(3)\n",
    "    df[\"Id\"] = os.path.splitext(os.path.basename(file_path))[0][0: 7] + '_' + df[\"date_str\"] + df[\"row_num\"]\n",
    "    df = df[['Date', 'Id', 'Description', 'Amount']]\n",
    "    return df\n",
    "\n",
    "\n",
    "# define the function of cleaning the BOA credit card\n",
    "def get_boa_cc(file_path):\n",
    "    df = pd.read_csv(file_path, dtype={\"Id\": str}).rename(columns = {'Posted Date': 'Date', 'Payee': 'Description'})\n",
    "    df[\"date_str\"] = pd.to_datetime(df[\"Date\"], format=\"%m/%d/%Y\").dt.strftime(\"%Y%m%d\")\n",
    "    df[\"row_num\"] =  (df.groupby(\"date_str\").cumcount() + 1).astype(str).str.zfill(3)\n",
    "    df[\"Id\"] = os.path.splitext(os.path.basename(file_path))[0][0: 7] + '_' + df[\"date_str\"] + df[\"row_num\"]\n",
    "    df = df[['Date', 'Id', 'Description', 'Amount']]\n",
    "    return df\n",
    "\n",
    "\n",
    "# define the function of cleaning the BOA debit card\n",
    "def get_boa_dc(file_path):\n",
    "    df = pd.read_csv(file_path, skiprows = 6)\n",
    "    df[\"date_str\"] = pd.to_datetime(df[\"Date\"], format=\"%m/%d/%Y\").dt.strftime(\"%Y%m%d\")\n",
    "    df[\"row_num\"] =  (df.groupby(\"date_str\").cumcount() + 1).astype(str).str.zfill(3)\n",
    "    df[\"Id\"] = os.path.splitext(os.path.basename(file_path))[0][0: 7] + '_' + df[\"date_str\"] + df[\"row_num\"]\n",
    "\n",
    "    df['Amount'] = df['Amount'].apply(lambda x: str(x).replace(\",\", \"\")).astype(float)\n",
    "    df = df[df['Amount'].notna()]\n",
    "    df = df[['Date', 'Id', 'Description', 'Amount']]\n",
    "\n",
    "    raw_df = pd.read_csv(file_path, nrows = 4)\n",
    "    beginning_bal, ending_bal = float(raw_df.iloc[0, 2].replace(\",\", \"\")), float(raw_df.iloc[3, 2].replace(\",\", \"\"))\n",
    "    \n",
    "    return df, beginning_bal, ending_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90bec8b-2ef5-4592-a7f3-975f28e8c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function of combining all the datasets to one\n",
    "def get_data(head, folder_path):\n",
    "    \n",
    "    df_list, folder_path = [], folder_path\n",
    "    df_folder_path = os.path.join(folder_path, head)\n",
    "    csv_files = [f for f in os.listdir(df_folder_path) if f.endswith('.csv')]\n",
    "    csv_files.sort(key = lambda x: x.replace('.csv', '').zfill(20))\n",
    "    if head == 'CC-5257':\n",
    "        used_func = get_dis_cc\n",
    "    elif head[0: 2] == 'CC':\n",
    "        used_func = get_boa_cc\n",
    "    elif head[0: 2] == 'DC' or head[0: 2] == 'SA':\n",
    "        used_func = get_boa_dc\n",
    "\n",
    "    if head[0: 2] == 'DC' or head[0: 2] == 'SA':\n",
    "        last_ending_bal = None\n",
    "        for file in csv_files:\n",
    "            file_path = os.path.join(df_folder_path, file)\n",
    "            df_list.append(used_func(file_path)[0])\n",
    "            \n",
    "            beginning_bal, ending_bal = used_func(file_path)[1], used_func(file_path)[2]\n",
    "            if last_ending_bal == None or beginning_bal == last_ending_bal: \n",
    "                last_ending_bal = ending_bal\n",
    "            else:\n",
    "                print('Wrong beginning balance:', file, beginning_bal, last_ending_bal)\n",
    "            \n",
    "    else:\n",
    "        for file in csv_files:\n",
    "            file_path = os.path.join(df_folder_path, file)            \n",
    "            df_list.append(used_func(file_path))\n",
    "            \n",
    "    combined_df = pd.concat(df_list)\n",
    "    combined_df['Card'] = head\n",
    "    combined_df[\"Date\"] = pd.to_datetime(combined_df[\"Date\"], format=\"%m/%d/%Y\").dt.date\n",
    "    \n",
    "    user_map = {'CC-5257': 'User1', 'CC-4253': 'User1', 'DC-9084': 'User1', 'CC-2853': 'User1',\n",
    "                'DC-8540': 'User2', 'CC-0401': 'User2', \n",
    "                'SA-7913': 'Savings'}\n",
    "    combined_df[\"User\"] = combined_df['Card'].map(user_map)\n",
    "    \n",
    "    combined_df = combined_df.sort_values('Date').reset_index(drop = True)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf5cca-356f-4102-a154-56512a35f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the start date of the file reading\n",
    "start_date = '2025-01-01'\n",
    "\n",
    "# read the datasets\n",
    "account_df_dict = {}\n",
    "\n",
    "for account in account_list:\n",
    "    df = get_data(account, folder_path)\n",
    "    df = df[df['Date'] >= datetime.strptime(start_date, \"%Y-%m-%d\").date()]\n",
    "    account_df_dict[account] = df\n",
    "    \n",
    "# combine all the datasets to one dataset\n",
    "combined_df = pd.concat([account_df_dict[account] for account in account_list]).sort_values('Date').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba99040-c7b9-46dc-8870-2c81a4e9c563",
   "metadata": {},
   "source": [
    "# Transaction Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb76af5e-dfec-4a20-ae9c-0f0ef11ec150",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../personal_envs/household-cashflow-analyzer\")\n",
    "from description_map import description_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dec285b-e087-41de-bd00-16e6be6362fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the description to the type\n",
    "for keyword, mapped_value in description_map.items():\n",
    "    combined_df.loc[combined_df[\"Description\"].str.contains(keyword, case=False, regex=False, na=False), \"Type\"] = mapped_value\n",
    "\n",
    "combined_df.loc[combined_df['Type'].isna(), 'Type'] = None\n",
    "combined_df['Original_Amount'] = combined_df['Amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eda1e8-da73-4761-9a90-0003c83ccf80",
   "metadata": {},
   "source": [
    "# Transaction Offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d5a001-4fdf-4be8-82b9-111ddf6b7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unnecessary rows and columns\n",
    "remove_list = ['Income: Reimbursement',\n",
    "               'CC Payback: Discover', \n",
    "               'CC Payback: BOA',\n",
    "               'Internal: from SA to DC',\n",
    "               'Internal: from DC to SA',\n",
    "               'Internal: from User1 to User2', \n",
    "               'Internal: from User2 to User1' ]\n",
    "\n",
    "for remove_item in remove_list:\n",
    "    if round(combined_df[combined_df['Type'] == remove_item]['Amount'].sum(), 2) == 0:\n",
    "        print('remove: ', remove_item)\n",
    "    else:\n",
    "        print('Not =0: ', remove_item)\n",
    "    combined_df = combined_df[combined_df['Type'] != remove_item]\n",
    "\n",
    "combined_df = combined_df[combined_df['Amount'] != 0][['Date', 'Id', 'Description', 'Original_Amount', 'Amount', 'Card', 'User', 'Type']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a2b6a0-a88f-4029-bd86-cd7deb37fe93",
   "metadata": {},
   "source": [
    "# Mapping Old File Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40e54e0-ada4-4133-b1c8-ef9f0b7ce90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defin the function of mapping the old excel file information to this new old\n",
    "def sub_old_data(new_df, old_file_name, folder_path):\n",
    "    old_df = pd.read_excel(os.path.join(folder_path, old_file_name), sheet_name = 'Sheet1')[['Id', 'Type', 'General_Type', 'Amount']]\n",
    "\n",
    "    comb_df = pd.merge(new_df, old_df, on = \"Id\", how = \"left\", suffixes = (\"\", \"_old\"))\n",
    "    \n",
    "    comb_df.loc[comb_df['Type'].isin([None, 'Other: Mobile Check']), 'Type'] = comb_df.loc[comb_df['Type'].isin([None, 'Other: Mobile Check']), 'Type_old']\n",
    "\n",
    "    comb_df.loc[comb_df['Type_old'].isin(['Omit: others']), 'Type'] = 'Omit: others'\n",
    "\n",
    "    comb_df.loc[(comb_df['Amount'] !=  comb_df['Amount_old']) & (comb_df['Amount_old'].notna()), 'Amount'] = comb_df.loc[(comb_df['Amount'] !=  comb_df['Amount_old']) & (comb_df['Amount_old'].notna()), 'Amount_old'] \n",
    "    \n",
    "    return comb_df[['Date', 'Id', 'Description', 'Original_Amount', 'Amount', 'Card', 'User', 'Type', 'General_Type']]\n",
    "\n",
    "# map the old excel file information to this new old\n",
    "old_file_name = 'combined_20251023142629.xlsx'\n",
    "combined_df_new = sub_old_data(combined_df, old_file_name, folder_path)\n",
    "\n",
    "# clean the columns of the dataset and add new columns\n",
    "combined_df_new[\"General_Type\"] = combined_df_new[\"Type\"].str.split(\":\", n = 1).str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29906d9c-c149-4ea6-80b6-0d8d283fa662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the dateset\n",
    "if round(combined_df_new.loc[combined_df_new[\"Type\"] == 'Omit: others', 'Original_Amount'].sum(), 2) != 0:\n",
    "    raise ValueError('The Type Omit: others do not sum up to 0.')\n",
    "elif round(combined_df_new['Original_Amount'].sum(), 2) != round(combined_df_new['Amount'].sum(), 2):\n",
    "    raise ValueError('The Original_Amount and Amount totals are not the same.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1ddbf6-5732-40cf-8eb8-3dc343c62a14",
   "metadata": {},
   "source": [
    "# Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d751b34-4722-43b6-b166-e70a082f0c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the file to EXCEL\n",
    "excel_name = f\"combined_{datetime.now().strftime('%Y%m%d%H%M%S')}.xlsx\"\n",
    "\n",
    "combined_df_new.to_excel(os.path.join(folder_path, excel_name), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b555d-4dc1-4040-9b8f-e0af496c491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the google_sheet_id, sheet_name and gsheet_credentials\n",
    "dotenv.load_dotenv(\"../personal_envs/household-cashflow-analyzer/.env\", override = True)\n",
    "spreadsheet_id, worksheet_name = os.getenv(\"gsheet_id\"), os.getenv(\"sheet_name\")\n",
    "gsheet_credentials = \"../personal_envs/household-cashflow-analyzer/gsheet_credentials.json\"\n",
    "\n",
    "# clean the Date column for uploading\n",
    "combined_df_new[\"Date\"] = pd.to_datetime(combined_df_new[\"Date\"]).dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# upload the data to Google Sheet\n",
    "gsheet_upload(gsheet_credentials, spreadsheet_id, worksheet_name, combined_df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f199c1-c9e8-409b-ac44-e54745aa6e07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
